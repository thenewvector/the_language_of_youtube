{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yt-dlp openai-whisper pydub\n",
    "\n",
    "# Dependencies (systemwide)\n",
    "#sudo apt install ffmpeg  # Linux\n",
    "#brew install ffmpeg      # macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Channel and/or Video Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yt_meta(url, limits):\n",
    "  options = {\n",
    "          'ignoreerrors': True,\n",
    "          'playlistend': limits,\n",
    "          'sleep_interval': 20,\n",
    "          'max_sleep_interval': 40,\n",
    "          'cookiesfrombrowser': ('chromium',),\n",
    "      }\n",
    "\n",
    "  with yt_dlp.YoutubeDL(options) as ydl:\n",
    "    channel_info = ydl.extract_info(url, download=False)\n",
    "  return channel_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Video URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_urls(db):\n",
    "    urls = []\n",
    "    for item in db[\"entries\"]:\n",
    "        urls.append(item[\"webpage_url\"])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the Data and Download Specific Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yt(video_url, start_count):\n",
    "    options = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'sleep_interval': 20,\n",
    "        'max_sleep_interval': 40,\n",
    "        'cookiesfrombrowser': ('chromium',),\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(options) as ydl:\n",
    "        try:\n",
    "            info = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "            # Проверяем получена ли инфа\n",
    "            # Если нет, то заполняем словарь данными об отсутствии инфы\n",
    "            if not isinstance(info, dict):\n",
    "                errors = \"no metadata\"\n",
    "                info = {\n",
    "                    \"entry_no\": start_count,\n",
    "                    \"title\": f\"no_title_{int(time.time())}\",\n",
    "                    \"duration\": 0,\n",
    "                    \"uploader\": \"unknown\",\n",
    "                    \"view_count\": 0,\n",
    "                    \"upload_date\": \"unknown\",\n",
    "                    \"url\": video_url,\n",
    "                }\n",
    "            else:\n",
    "                errors = None\n",
    "\n",
    "        except Exception as e:\n",
    "            errors = str(e)\n",
    "            info = {\n",
    "                \"entry_no\": start_count,\n",
    "                \"title\": f\"no_title_{int(time.time())}\",\n",
    "                \"duration\": 0,\n",
    "                \"uploader\": \"unknown\",\n",
    "                \"view_count\": 0,\n",
    "                \"upload_date\": \"unknown\",\n",
    "                \"url\": video_url,\n",
    "            }\n",
    "\n",
    "        # Обрабатываем названия для имени файла и диреткории\n",
    "        max_file = 200\n",
    "        max_dir = 7\n",
    "        \n",
    "        video_title = info[\"title\"].lower()\n",
    "        normalized_title = re.sub(r'[\\\\/*?:\"<>|!]', \"\", video_title)\n",
    "        normalized_title = re.sub(r\"[^\\x00-\\x7F]\", \"\", normalized_title)\n",
    "        title_to_filename = re.sub(r'\\s+', \"_\", normalized_title.strip())\n",
    "        \n",
    "        if len(title_to_filename) > max_file:\n",
    "            title_to_filename = title_to_filename[:max_file].strip()\n",
    "\n",
    "        interim_dir = info['uploader'].lower()\n",
    "        directory = re.sub(r'[^\\w\\d]', \"\", interim_dir.strip())\n",
    "\n",
    "        if len(directory) > max_dir:\n",
    "            directory = directory[:max_dir].strip()\n",
    "        else:\n",
    "            directory = directory + (\"x\" * (max_dir - len(directory)))\n",
    "\n",
    "        # Задаем имя файла и путь\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        output_file = os.path.join(directory, f\"{start_count}_{directory}_{title_to_filename}.%(ext)s\")\n",
    "        options['outtmpl'] = output_file\n",
    "\n",
    "        # Качаем видео\n",
    "        try:\n",
    "            ydl = yt_dlp.YoutubeDL(options)\n",
    "            ydl.download([video_url])\n",
    "        \n",
    "        except Exception as e:\n",
    "            errors = str(e)\n",
    "\n",
    "    result = {\n",
    "        \"entry_no\": start_count,\n",
    "        \"title\": info[\"title\"],\n",
    "        \"directory\": directory,\n",
    "        \"filename\": f\"{start_count}_{directory}_{title_to_filename}.webm\",\n",
    "        \"duration\": info[\"duration\"],\n",
    "        \"uploader\": info[\"uploader\"],\n",
    "        \"view_count\": info[\"view_count\"],\n",
    "        \"upload_date\": info[\"upload_date\"],\n",
    "        \"url\": video_url,\n",
    "        \"errors\": errors,\n",
    "    }\n",
    "\n",
    "    start_count += 1\n",
    "\n",
    "    return result, start_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dl_and_make_db(video_urls, start_count):\n",
    "    downloaded_videos = []\n",
    "    for item in video_urls:\n",
    "        result = scrape_yt(item, start_count)\n",
    "        downloaded_videos.append(result[0])\n",
    "        start_count = result[1]\n",
    "    return downloaded_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(dl_db):\n",
    "    directory = dl_db[0]['directory']\n",
    "    files_to_transcribe = os.listdir(directory)\n",
    "    \n",
    "    transcripts = []\n",
    "    for item in dl_db:\n",
    "        filename = item[\"filename\"]\n",
    "        \n",
    "        if isinstance(files_to_transcribe, list):\n",
    "            if filename in files_to_transcribe:\n",
    "                path = os.path.join(directory, filename)\n",
    "                try:\n",
    "                    model = whisper.load_model(\"small\")\n",
    "                    result = model.transcribe(path, language=\"en\", task=\"transcribe\", temperature=0, best_of=3, fp16=False)\n",
    "                    item[\"transcript\"] = result[\"text\"]\n",
    "                \n",
    "                except Exception as e:\n",
    "                    error = str(e)\n",
    "                    item[\"transcript\"] = f\"Something went wrong (with the model): {error}\"\n",
    "            else:\n",
    "                item[\"transcript\"] = f\"Something went wrong. It looks like the entry exists, but the file to transcribe is missing.\"\n",
    "        else:\n",
    "            item[\"transcript\"] = f\"Something went wrong. Maybe, the directory is empty.\"\n",
    "    \n",
    "    return dl_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Full Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphamx_full_db = transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(\"https://www.youtube.com/@alpham/videos\", 50)),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alphamx_full_db[49])\n",
    "print(type(alphamx_full_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def export_to_json(db, name_of_file):\n",
    "    try:\n",
    "        if isinstance(db, list):\n",
    "            json_file = f\"{name_of_file}.json\"\n",
    "            with open(json_file, \"w\") as file:\n",
    "                json.dump(db, file, indent=4)\n",
    "        else:\n",
    "            print(\"Something's wrong with your DB; skipping this step\")\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        print(f\"Something's wrong with the JSON export process: {error}; skipping this step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_transcripts(db, name_of_file):\n",
    "    try:\n",
    "        if isinstance(db, list):\n",
    "            txt_file = f\"{name_of_file}.txt\"\n",
    "            with open(txt_file, \"a\") as file:\n",
    "                for item in db:\n",
    "                    file.write(item[\"transcript\"] + \"\\n\\n\\n\")\n",
    "        else:\n",
    "            print(\"Something's wrong with your DB; skipping this step\")\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        print(f\"Something's wrong with the export: {error}; skipping this step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"alphamx_full_db\"\n",
    "export_to_json(alphamx_full_db, name)\n",
    "\n",
    "name = \"alphamx_transcrips\"\n",
    "export_transcripts(alphamx_full_db, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMF\n",
    "teachin_full_db = transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(\"https://www.youtube.com/@JosecZuniga/videos\", 50)),50))\n",
    "\n",
    "name = \"teachin_full_db\"\n",
    "export_to_json(teachin_full_db, name)\n",
    "\n",
    "name = \"teachin_transcrips\"\n",
    "export_transcripts(teachin_full_db, name)\n",
    "\n",
    "# The Style OG\n",
    "thestyl_full_db = transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(\"https://www.youtube.com/@TheStyleOG/videos\", 50)),100))\n",
    "\n",
    "name = \"thestyl_full_db\"\n",
    "export_to_json(thestyl_full_db, name)\n",
    "\n",
    "name = \"thestyl_transcrips\"\n",
    "export_transcripts(thestyl_full_db, name)\n",
    "\n",
    "# RMRS\n",
    "realmen_full_db = transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(\"https://www.youtube.com/@RealMenRealStyle/videos\", 50)),150))\n",
    "\n",
    "name = \"realmen_full_db\"\n",
    "export_to_json(realmen_full_db, name)\n",
    "\n",
    "name = \"realmen_transcrips\"\n",
    "export_transcripts(realmen_full_db, name)\n",
    "\n",
    "# 40 Over\n",
    "fourtyo_db = transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(\"https://www.youtube.com/@40OverFashion/videos\", 50)),200))\n",
    "\n",
    "name = \"fourtyo_db\"\n",
    "export_to_json(fourtyo_db, name)\n",
    "\n",
    "name = \"fourtyo_transcrips\"\n",
    "export_transcripts(fourtyo_db, name)\n",
    "\n",
    "# Brock\n",
    "brockmc_db = transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(\"https://www.youtube.com/@BrockMcGoff/videos\", 50)),250))\n",
    "\n",
    "name = \"brockmc_db\"\n",
    "export_to_json(brockmc_db, name)\n",
    "\n",
    "name = \"brockmc\"\n",
    "export_transcripts(brockmc_db, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_one(db):\n",
    "    path = os.path.join(db[0][\"directory\"], db[0][\"filename\"])\n",
    "    model = whisper.load_model(\"small\")\n",
    "    result = model.transcribe(path, language=\"en\", task=\"transcribe\", temperature=0, best_of=3, fp16=False)\n",
    "    db[0][\"transcript\"] = result[\"text\"]\n",
    "    return db[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"YouTube Register\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = \"https://www.youtube.com/@clarkkegley/videos https://www.youtube.com/@mattdavella/videos https://www.youtube.com/@howtobeast/videos https://www.youtube.com/@mkbhd/videos https://www.youtube.com/@AndrewPaul1/videos https://www.youtube.com/@JeffSu/videos https://www.youtube.com/@NicholasGarofola/videos https://www.youtube.com/@betterideas/videos https://www.youtube.com/@TeddyBaldassarre/videos https://www.youtube.com/@ManTalks/videos https://www.youtube.com/@Christinamychas/videos https://www.youtube.com/@JimmyTriesWorld/videos https://www.youtube.com/@spoonfedstudy/videos https://www.youtube.com/@GabeBult/videos https://www.youtube.com/@JesseJamesWest/videos https://www.youtube.com/@danmartell/videos https://www.youtube.com/@IAmMarkManson/videos https://www.youtube.com/@LeviHildebrandYT/videos https://www.youtube.com/@CarlMurawski/videos https://www.youtube.com/@FlyWithJohnnyThai/videos\"\n",
    "channel_urls = everything.split()\n",
    "print(channel_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_register_full_db = []\n",
    "start_count = 0\n",
    "\n",
    "for item in channel_urls:\n",
    "    yt_register_full_db.extend(transcribe_audio(batch_dl_and_make_db(get_video_urls(scrape_yt_meta(item, 15)), start_count)))\n",
    "    start_count += 15\n",
    "\n",
    "name = \"yt_register_full_db\"\n",
    "export_to_json(yt_register_full_db, name)\n",
    "\n",
    "name = \"yt_register_transcrips\"\n",
    "export_transcripts(yt_register_full_db, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
